# 一网打尽 Flink 高频面试题

Apache Flink 是一个分布式处理引擎和框架，用于对无界数据和有界数据流进行有状态计算。Flink 被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。Apache Flink 是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源流处理框架。

在大数据岗位的面试中，尤其是对实时处理比较感兴趣的企业，面试中对于 Flink 的考察已经非常普遍，本文整理了 Flink 的高频面试题，并做了简单的思路分析。

### 面试题一：公司怎么提交实时任务？

我们每次提交都会常见一个新的 Flink 集群，为每个 job 提供一个 yarn-session，任务之间相互独立，互不影响，方便管理。任务执行完成之后创建的集群也会消失。

集群默认只有一个 Job Manager。但是为了防止单点故障，我们配置了高可用。我们公司一般配置一个主Job Manager，两个备用 Job Manager，然后结合 Zookeeper 的使用，来达到高可用。

### 面试题二：怎么做压力测试和监控？

我们一般碰到的压力来自以下几个方面：

一、产生数据流的速度如果过快，而下游的算子消费不过来的话，会产生背压问题。背压的监控可以使用 Flink Web UI（localhost:8081）来做可视化监控，一旦报警就能知道。一般情况下背压问题的产生可能是由于 sink 这个操作符没有优化好，做一下优化就可以了。比如如果是写入 ElasticSearch，那么可以改成批量写入，可以调大 ElasticSearch 队列的大小等等策略。

二、设置水位线的最大延迟时间这个参数，如果设置的过大，可能造成内存的压力。可以设置的最大延迟时间小一写，然后把迟到元素发送到侧输出流中。晚一点更新结果。或者使用类似于 RocksDB 这样的状态后端，RocksDB 会开辟堆外存储空间，但 IO 速度会变慢，需要权衡。

三、还有就是滑动窗口的长度如果过长，而滑动距离很短的话，Flink 的性能会下降的很厉害。

参照连接：[Flink 滑动窗口优化](https://www.infoq.cn/article/sIhs_qY6HCpMQNblTI9M)

四、状态后端使用 RocksDB，还没有碰到被撑爆的问题。

五、尽量使用滚动窗口，这样会大大减轻存储的压力。

六、如果想要达到极限的低延迟，可以考虑使用处理时间（Processing Time）。

七、义务逻辑的编写是最重要的，在算子中（例如 processingElement，onTimer）业务逻辑一定要尽可能的简单，而不是特别复杂的业务逻辑（举个极端的例子，机器学习这种 CPU 密集型的程序，十几张表的 Join）。如果业务逻辑很复杂的话，将会阻塞数据流的向下传递。性能会急剧下降。

### 面试题三：为什么使用 Flink 替代 Spark？

一、Flink 是真正的流处理，演示在毫秒级，Spark Streaming 是微批，延迟在秒级。

二、Flink 可以处理事件事件，而 Spark Streaming 只能处理机器事件，无法保证时间语义的正确性。

三、Flink 的检查点算法比 Spark Streaming 更加灵活，性能更高。Spark Streaming 的检查点算法是在每个 stage 结束以后，才会保存检查点。

四、Flink 易于实现端到端一致性。

### 面试题四：Flink 的 CheckPoint 存在哪里？

状态后端。内存，文件系统，RocksDB

### 面试题五：如果下级存储不支持事务，Flink 如何保证 exactly-once？

端到端的 exactly-once 对 sink 的要求较高，具体实现主要有幂等写入和事务性写入这两种方式。幂等写入的场景依赖于业务逻辑，更常见的使用事务性写入。而事务性写入又有预写日志（WAL）和两阶段提交（2PC）两种方式。

如果外部系统不支持事务，那么可以用预写日志的方式，把结果数据先当成状态保存，然后在收到 checkpoint 完成的通知时，一次性写入 sink 系统。

### 面试题六：说一下 Flink 的状态机制

Flink 内置的很多算子，包括源 source，数据存储 sink 都是由状态的。在 Flink 中，状态始终与特定算子相关联。Flink 会以 checkpoint 的形式对各个任务的状态进行快照，用于保证故障恢复时的状态一致性。Flink 通过状态后端来管理状态和 checkpoint 的存储，状态后端可以有不同的配置选择。

### 面试题七：海量 key 去重问题

考虑一个实时场景：双十一场景，滑动窗口长度为 1 小时，滑动距离为 10 秒钟，亿级用户，怎样计算 uv。

解答：使用类似于 scala 的 set 数据结构或者 redis 的 set 显然是不行的，因为可能有上亿个 key，内存放不下。所有可以考虑使用布隆过滤器（Bloom Filter）来去重。

### 面试题八：Flink 的 CheckPoint 和 Spark 的比较

Spark Streaming 的 checkpoint