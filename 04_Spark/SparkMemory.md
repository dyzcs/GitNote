# Spark 内存管理

## 1 堆内和堆外内存规划

作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-Heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-Heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内内存受到 JVM 统一管理，堆外内存是直接向操作系统进行内存的申请和释放。

![Spark 内存管理](SparkMemory.assets\01_sparkmemory.png)

### 1.1 堆内内存

堆内内存的大小，由 Spark 应用程序启动时的 *-executor-memory* 或 *spark.executor.memeory* 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Executor）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同。

Spark 对堆内内存的管理师一种逻辑上的"规划式"的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，具体流程如下：

1. Spark 在代码中 new 一个对象实例；

 	2. JVM 从堆内内存分配空间，创建对象并返回对象引用；
 	3. Spark 保存该对象的引用，记录该对象占用的内存。

释放流程如下：

1. Spark 记录该对象释放的内存，删除该对象的引用；

 	2. 等待 JVM 的垃圾回收机制释放该对象占用的堆内内存；

我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转换为连续空间或块存储，在访问时则需要进行序列化的逆过程——反序列化，将字节流转换为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。

对于 Spark 中序列化的对象，由于是字节流的像是，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性的采样近似估计而得，而并不是每次新增的数据项都会计算一次占用内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远超出预期。从外，在被 Spark 标记为释放的对象实例，很有可能在某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就没有办法完全避免内存溢出（OOM，*OutOfMemory*）的异常。

虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可用决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提高内存的利用率，减少异常的出现。

### 1.2 堆外内存

**为了进一步优化内存的使用以及提高 shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。**

堆外内存意味着把存储对象分配在 Java 虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机），这样做的结果就是能保持一个较小的堆，以减少垃圾收集对应用的影响。

利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外内的存储内存时不在基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精准的申请和释放（堆外内存之所以能后被精准的申请和释放，是由于内存的申请和释放不在通过 JVM 机制，而是直接向操作系统申请，JVM 对于内存的清理是无法准确指定时间点的，因此无法实现精确的释放），而且序列化的数据占用的空间可以被精确计算，所有相比堆内内存来说降低了管理的难度，也降低了误差。

在默认情况下堆外内存并不启用，可通过配置 *spark.memory.offHeap.enabled* 参数启用，并由 *spark.memory.offHeap.size* 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中并发任务贡献存储内存和执行内存。

## 2 内存空间分配

### 2.1 静态内存管理

在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均是固定的，但用户可以在应用程序启动前进行配置，堆内内存的分配如下：

![静态_堆内内存分配](SparkMemory.assets\02_staticonheapmemory.png)

可以看到，可用的堆内内存的大小需要按照下列方式进行计算：

```tex
可用的存储内存 = 
systemMaxMemory * spark.storage.memoryFraction * spark.storage.safety Fraction
可用的执行内存 = 
systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safety Fraction
```

其中 systemMaxMemory 取决于当前 JVM 堆内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。

Storage内存和Execution内存都有预留空间，目的是防止OOM，因为Spark堆内内存大小的记录是不准确的，需要留出保险区域。

堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。

![静态_堆外内存分配](SparkMemory.assets\03_staticoffheapmemory.png)

静态内存管理机制实现起来较为简单，但如果用户不熟悉Spark的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成"一半海水，一半火焰"的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。

### 2.2 统一内存管理

Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域，统一内存管理的堆内内存结构如图所示：

![统一_堆内内存分配](SparkMemory.assets\04_unifiedonheapmemory.png)

统一内存管理的堆外内存结构如下图所示：

![统一_堆外内存分配](SparkMemory.assets\05_unifiedoffheapmemory.png)

其中最重要的优化在于动态占用机制，其规则如下：

1. 设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围；
2. 双方的空间都不足时，则存储到磁盘；若己方空间不足而对方空余时，可借用对方的空间（存储空间不足是指不足以放下一个完整的 Blcok）；
3. 执行内存的空间被对方占用后，可让对方将占用的部分转存到磁盘，然后"归还"借用的空间；
4. 存储内存的空间被对方占用后，无法让对方"归还"，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。

统一内存管理的动态引用机制如图所示：

![统一内存管理动态引用](SparkMemory.assets\06_dynamicreference.png)