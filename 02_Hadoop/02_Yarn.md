# Yarn

## 1 Yarn 是什么

Apache YARN（Yet Another Resource Negotiator）是 Hadoop 的集群资源管理系统。Yarn 被引入 Hadoop 2，最初是为了盖申 MapReduce 的实现， 但它具有足够的通用性，同样可以支持其他的分布式计算模式。

Yarn 提供请求和使用集群资源的 API，但这些 API 很少直接用于用户代码。相反，用户代码中用的是分布式计算框架提供的更高层 API，这些 API 建立在 Yarn 之上，且向用户隐藏了资源管理细节。下图对此进行了描述，一些分布式计算框架（MapReduce，Spark 等等）作为 Yarn 应用运行在集群计算层（Yarn）和集群存储层（HDFS 和 HBase）上。

<img src="https://dyz-picbed.obs.cn-south-1.myhuaweicloud.com/03_yarn/01_yarn.png" alt="Yarn 使用场景" style="zoom: 40%;" />

还有一层应用是建立在上图 Application 之上。如 Pig、Hive 等都是运行在 MapReduce、Spark 或 Tez（或三个都可）之上的处理框架，它们不和 Yarn 直接打交道。

## 2 Yarn 运行机制

Yarn 通过两类长期运行的守护进程提供自己的核心服务：管理集群上资源使用的资源管理器（resource manager）、运行在集群中所有节点上且能够启动和监控容器（container）的节点管理器（node manager）。容器用于执行特定应用程序的进程。每个容器都有资源限制（内存、CPU等）。一个容器可以是一个 Unix 进程，也可以是一个 Linux cgroup，取决于 Yarn 的配置，下图描述了 Yarn 是如何运行一个应用。

<img src="https://dyz-picbed.obs.cn-south-1.myhuaweicloud.com/03_yarn/02_yarnrunjob.png" alt="Yarn 运行应用" style="zoom: 50%;" />

为了在 Yarn 上运行一个应用，首先，客户端联系资源管理器，要求它运行一个 application master 进程（步骤 1）。然后，资源管理器找到一个能够在容器中启动 application master 的节点管理器（步骤 2a 和 2b）。准确的说，application master 一旦运行起来后能做些什么依赖于应用本身。有可能是所处的容器中简单运行一个计算，并将结果返回给客户端；或是向资源管理器请求更多的容器（步骤 3），以用于运行一个分布式计算（步骤 4a 和 4b）。后者是 MapReduce Yarn 应用中所做的事情。

**注意**，Yarn 本身不会为应用的各部分（客户端，master 和进程）彼此间通信提供任何手段。大多数重要的 Yarn 应用使用某种形式的远程通信机制（例如 Hadoop 中的 RPC 层）来向客户端传递状态更新和返回结果，但是这些通信机制都是属于各应用的。

### 2.1 资源请求

Yarn 有一个灵活的资源请求模型。当请求多个容器时，可以指定每个容器需要的计算机资源数量（内存和 CPU），还可以指定对容器的本地限制要求。

本地化对于确保分布式数据处理算法高效使用集群带宽非常重要，因此，Yarn 允许一个应用为所申请的容器执行本地限制。本地限制可以用于申请位于指定节点或机架，或集群中任何位置（机架外）的容器。

有时本地限制无法被满足，这种情况下要么不分配资源，或者可以选择放松限制，例如，一个节点由于已经运行了别的容器而无法再启动新的容器，这是如果有应用请求该节点，则 Yarn 将尝试在同一机架的其他节点上启动一个容器，如果还不行，则会尝试集群中的任何一个节点。

通常情况下，当启动一个容器用于处理 HDFS 数据块时，应用将会向这样的节点申请容器：存储该数据块的三个复本的几点，或是存储这些复本的机架中的一个节点。如果有申请失败，则申请集群中的任意节点。

Yarn 应用可以在运行中的任意时刻提出资源申请。例如，可以在最开始提出所有的请求，或者为了满足不断变化的应用需要，采取更为动态的方式在需要更多资源时提出请求。

Spark 采用了第一种方式，在集群上启动固定数量的执行器。另一方面，MapReduce 则分两步走，在最开始时申请 map 任务容器，reduce 任务容器的启动则放在后期。同样，如果任何任务出现失败，将会另外申请容器以重新运行失败的任务。

### 2.2 应用生命期

Yarn 应用的生命周期我们可以按照**应用到用户运行的作业之间的映射关系**对应用进行分类，最简单的模型是一个用户作业对应一个应用，这也是 MapReduce 采取的方式。

第二种模型是，作业的每个工作流或每个用户对话对应一个应用。这种方法要比第一种情况效率更高，因为容器可以在作业之间重用，并且有可能缓存作业之间的中间数据。Spark 采用的是这种模型。

第三种模型是，多个用户共享一个长期运行的应用。这种应用通常是作为一种协调者的角色在运行。由于避免了启动新 application master 带来的开销，一个总是开启的 application master 意味着用户将获得非常低延迟的查询响应。

 ## 3 Yarn 资源调度

理想情况下，Yarn 应用发出的资源请求应该立刻给与满足。然而现实中资源是有限的，在一个繁忙的集群上，一个应用经常需要等待次啊能得到所需的资源。Yarn 调度器的工作就是根据既定策略为应用分配资源。

### 3.1 调度选项

Yarn 中有三种调度器可选：**FIFO调度器**（FIFO Scheduler），**容量调度器**（Capacity Scheduler）和**公平调度器**（Fair Scheduler）。FIFO 调度器将应用放置在一个队列中，然后按照提交的顺序（先进先出）运行应用。首先为队列中第一个应用的请求分发资源，第一个应用的请求被满足后再依次为队列中下一个应用服务。

FIFO 调度器的优点是，简单易懂，不需要任何配置，但是不适合共享集群。大的应用会占用集群中的所有资源，所以每个应用必须等待直到轮到自己运行，在一个共享集群中，更适合使用容量调度器或公平调度器。这两中调度器都允许长时间运行的作业能及时完成，同时也允许正在进行较小临时查询的用户能够在合理的时间内得到返回结果。

下图描述了调度器之间的差异性，当使用FIFO调度器（I）时，小作业一直被阻塞，直到大作业完成。使用容量调度器时（II），一个独立的专门队列保证小作业一提交就可以启动，由于队列容量是为那个队列中的作业所保留的，因此这种策略是以整个集群的利用率为代价的。这意味着与使用 FIFO 调度器相比，大作业执行的时间要长。使用公平调度器时（III），不需要预留一定量的资源，因为调度器会在所有运行的作业之间冬天平平衡资源，第一个（大）作业启动时，它也是唯一运行的作业，因而获得集群中所有的资源。的那个第二个（小）作业启动时，它被分配到集群的一半资源，这样每个作业都能公平共享资源。

注意，从第二个作业的启动必须要等待第一个作业使用的容器用完并释放资源。当小作业结束且不再申请资源后，大作业再将回去再次使用全部的集群资源。最终的效果是：既得到了较高的集群利用率，又能保证小作业能及时完成。

<img src="https://dyz-picbed.obs.cn-south-1.myhuaweicloud.com/03_yarn/03_yarnscheduler.png" alt="yarn 调度器" style="zoom: 33%;" />